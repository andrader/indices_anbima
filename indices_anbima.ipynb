{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from time import sleep\n",
    "from datetime import date, datetime\n",
    "import datatest\n",
    "import sqlite3\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import unidecode\n",
    "\n",
    "tqdm.pandas(leave=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.anbima.com.br/informacoes/ima/ima-sh-down.asp'\n",
    "params = {\n",
    "    \"Idioma\": \"PT\",\n",
    "    \"Dt_Ref\": \"20/03/2021\",\n",
    "    \"DataIni\": \"06/01/2020\",\n",
    "    \"DataFim\": \"20/03/2021\",\n",
    "    \"Indice\": \"quadro-resumo\",\n",
    "    \"Consulta\": \"Ambos\",\n",
    "    \"saida\": \"csv\"\n",
    "}\n",
    "\n",
    "nomes_validos = [\n",
    "        'indice', 'data_referencia', 'numero_indice', 'variacao_diaria',\n",
    "        'variacao_mes', 'variacao_ano', 'variacao_12_meses',\n",
    "        'variacao_24_meses', 'peso', 'duration', 'carteira_a_mercado',\n",
    "        'numero_operacoes', 'quant_negociada_titulos', 'valor_negociado', 'pmr',\n",
    "        'convexidade', 'yield', 'redemption_yield'\n",
    "    ]\n",
    "\n",
    "valid_dtypes = {\n",
    "    'indice': 'O',\n",
    "    'data_referencia': 'datetime64[ns]',\n",
    "    'numero_indice': 'float64',\n",
    "    'variacao_diaria': 'float64',\n",
    "    'variacao_mes': 'float64',\n",
    "    'variacao_ano': 'float64',\n",
    "    'variacao_12_meses': 'float64',\n",
    "    'variacao_24_meses': 'float64',\n",
    "    'peso': 'float64',\n",
    "    'duration': 'O',\n",
    "    'carteira_a_mercado': 'O',\n",
    "    'numero_operacoes': 'float64',\n",
    "    'quant_negociada_titulos': 'float64',\n",
    "    'valor_negociado': 'float64',\n",
    "    'pmr': 'O',\n",
    "    'convexidade': 'float64',\n",
    "    'yield': 'float64',\n",
    "    'redemption_yield': 'float64'\n",
    "}\n",
    "\n",
    "# lista de user agents\n",
    "uas = pd.read_table('input/user-agents.txt',names=['ua'],skiprows=4,squeeze=True)\n",
    "# lista de feriados anbima\n",
    "fer = pd.read_excel('input/feriados_nacionais.xls',skipfooter=9, usecols=['Data'], parse_dates=['Data'], squeeze=True)\n",
    "bday = pd.offsets.CDay(holidays=fer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def dtf(x): return x.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "def clean_names(s, to_remove=[]):\n",
    "    s2 = s.map(lambda x: unidecode.unidecode(x))\n",
    "    for c in to_remove:\n",
    "        s2 = s2.str.replace(c, \" \", regex=False)\n",
    "    return s2.str.strip().str.split().str.join(\"_\").str.lower()\n",
    "\n",
    "\n",
    "def get_indices_anbima(dt, wait=True):\n",
    "    \"\"\"\n",
    "    dt: str '%d/%m/%Y' ou dt obj\n",
    "    \"\"\"\n",
    "    if wait:\n",
    "        if isinstance(wait,bool): wait = random.randint(1,3)\n",
    "        sleep(wait)\n",
    "    \n",
    "    headers = {\"User-Agent\": np.random.choice(uas)}\n",
    "    params[\"Dt_Ref\"] = params[\"DataIni\"] = params[\"DataFim\"] = dt.strftime(\"%d/%m/%Y\")\n",
    "    r = requests.get(url, params=params, stream=True, headers=headers)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(io.StringIO(r.text),\n",
    "                         sep=\";\",decimal=\",\",thousands=\".\",na_values=\"--\",\n",
    "                         skiprows=1,parse_dates=[\"Data de Referência\"],dayfirst=True,)\n",
    "        assert df.shape[0] > 0, \"0 linhas. \"\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        print(dt, e, r.text, sep='\\n')\n",
    "        df = pd.DataFrame(columns=nomes_validos)\n",
    "\n",
    "    # trata col_names e dtypes\n",
    "    to_remove = [\"<BR>\",\"1.000\",\"R$ mil\",\" de \",\" no \",\"d.u.\",\"%\",\"(\",\")\",\"*\",\".\",]\n",
    "    df = df.set_axis(clean_names(df.columns, to_remove), axis=1).astype(valid_dtypes)\n",
    "\n",
    "    # validacao\n",
    "    datatest.validate(df.columns, nomes_validos)\n",
    "    datatest.validate(df.dtypes, valid_dtypes)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_max_dt_db(db_table_name, db_name='data.sqlite', default_dt='2001-12-03'):\n",
    "    # tenta pegar data mais antiga na base\n",
    "    try:\n",
    "        with sqlite3.connect(db_name) as conn:\n",
    "            dt_max = pd.read_sql_query(f\"select max(data_referencia) data_referencia from {db_table_name}\",\n",
    "                                       conn, parse_dates=['data_referencia']).squeeze()\n",
    "    except Exception as e:\n",
    "        print(e, 'getting min available date')\n",
    "        dt_max = pd.Timestamp(default_dt).normalize()\n",
    "    return dt_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afd979756f04e10a3d10be705b62d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Datas 31/01/2002->19/03/2021. Meses'), FloatProgress(value=0.0, max=230.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Scraping 2002-02'), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d785861a5bbc40f381f12ddbfeb9f7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Scraping 2002-03'), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-269-a57c7e0a49a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mscrape_indices_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data.sqlite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-269-a57c7e0a49a8>\u001b[0m in \u001b[0;36mscrape_indices_to\u001b[1;34m(db_table_name, db_name)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'day'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'Scraping {month.strftime(\"%Y-%m\")}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# scrape bdays in month\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_indices_anbima\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;31m# add df to db\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \"\"\"\n\u001b[1;32m--> 274\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    275\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[0mobjs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mobjs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-269-a57c7e0a49a8>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'day'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'Scraping {month.strftime(\"%Y-%m\")}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# scrape bdays in month\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_indices_anbima\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;31m# add df to db\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-268-c2b7646a679b>\u001b[0m in \u001b[0;36mget_indices_anbima\u001b[1;34m(dt, wait)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwait\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"User-Agent\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def scrape_indices_to(db_table_name, db_name='data.sqlite'):\n",
    "    # generate date series\n",
    "    dt_start = get_max_dt_db(db_table_name) + bday # next Bizday\n",
    "    dt_end = pd.Timestamp.today().normalize() - bday # last Bizday\n",
    "    dates = pd.bdate_range(dt_start, dt_end, freq=\"C\", holidays=fer).to_series()\n",
    "    \n",
    "    if len(dates)==0:\n",
    "        print('Nothing to update!')\n",
    "    \n",
    "    for month, days in tqdm(dates.groupby(pd.Grouper(freq='MS')),unit='mês',\n",
    "                            desc=f'De {dtf(dt_start)} até {dtf(dt_end)}. Meses'):\n",
    "        # progress bar\n",
    "        pbar = tqdm(days,leave=False,unit='day', desc=f'Scraping {month.strftime(\"%Y-%m\")}')\n",
    "        # scrape bdays in month\n",
    "        df = pd.concat((get_indices_anbima(dt) for dt in pbar), ignore_index=True)\n",
    "        # add df to db\n",
    "        with sqlite3.connect(db_name) as conn:\n",
    "            df.to_sql(table_name, conn, if_exists=\"append\", index=False)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "scrape_indices_to('data2', 'data.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleta Registros Inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def run(q):\n",
    "#     with sqlite3.connect(r'C:\\Users\\rubens\\indices_anbima\\data.sqlite') as conn:\n",
    "#         res = conn.execute(q).fetchall()\n",
    "#     return res\n",
    "\n",
    "# ndel = run(\"SELECT count(*) FROM data WHERE indice LIKE 'No columns to parse from file%'\")\n",
    "# if input(f'To delete {ndel} rows?[y/n]')=='y':\n",
    "#     # cria tabela de backup\n",
    "#     run(\"DROP TABLE IF EXISTS data_bkp\")\n",
    "#     run(\"CREATE TABLE data_bkp AS SELECT * FROM data\")\n",
    "#     # deleta linhs onde indice é 'No columns to parse from file...'\n",
    "#     run(\"DELETE FROM data WHERE indice LIKE 'No columns to parse from file%'\")\n",
    "#     print('Deleted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
